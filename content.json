{"meta":{"title":"ibabyblue's Blog","subtitle":"心之所向 身之所往","description":"一名就职于猎豹移动的iOS Coder","author":"ibabyblue","url":"http://yoursite.com","root":"/"},"pages":[{"title":"categories","date":"2020-04-10T05:36:13.000Z","updated":"2020-04-10T05:36:33.765Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-10T05:36:45.000Z","updated":"2020-04-10T05:37:02.465Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"iOS音视频开发-音频硬编码-AudioToolbox-PCMToAAC","slug":"iOS音视频开发-音频硬编码-AudioToolbox-PCMToAAC","date":"2018-02-26T07:11:40.000Z","updated":"2020-04-10T07:18:29.155Z","comments":true,"path":"2018/02/26/iOS音视频开发-音频硬编码-AudioToolbox-PCMToAAC/","link":"","permalink":"http://yoursite.com/2018/02/26/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91-%E9%9F%B3%E9%A2%91%E7%A1%AC%E7%BC%96%E7%A0%81-AudioToolbox-PCMToAAC/","excerpt":"","text":"之前几篇文章记录了视频的软、硬编码过程，接下来将记录下音频的软、硬编码过程，学习、工作之余，以免忘记。视频编码地址：iOS音视频开发-视频会话捕捉iOS音视频开发-视频硬编码(H264)iOS音视频开发-视频软编码(x264编码H.264文件)iOS音视频开发-视频软编码(FFmpeg+x264编码H.264文件) PCM数据PCM(Pulse Code Modulation)也被称为脉冲编码调制。PCM音频数据是未经压缩的音频采样数据裸流，它是由模拟信号经过采样、量化、编码转换成的标准的数字音频数据。移动端对音频的实时采集编码传输，一般为将采集的音频数据设置为PCM格式数据，然后将PCM编码为AAC格式数据，以便后续传输。PCM的数据格式，这里有篇文章介绍的很好，后续代码中的采样率、声道等均参考此文章设置。PCM数据格式文章地址：点这里 ADTSADTS全称是(Audio Data Transport Stream)，是AAC的一种十分常见的传输格式。将PCM数据编码为AAC的时候需要将每帧的AAC数据添加ADTS header，否则将无法解码播放。ADTS数据格式分为两部分：固定头部：adts_fixed_header可变头部：adts_variable_header详见Wiki，地址在文章末尾。 主要代码1、音频捕获代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201#import &quot;BBAudioCapture.h&quot;#import &lt;AVFoundation&#x2F;AVFoundation.h&gt;#import &quot;BBAudioConfig.h&quot;#import &quot;BBAudioHardEncoder.h&quot;#import &quot;BBAudioHardEncoder.h&quot;@interface BBAudioCapture ()&#123; AudioComponentInstance _outInstance;&#125;@property (nonatomic, assign) AudioComponent component;@property (nonatomic, strong) AVAudioSession *session;@property (nonatomic, strong) BBAudioHardEncoder *encoder;@property (nonatomic, strong) NSFileHandle *handle;@end@implementation BBAudioCapture#pragma mark -- 对象销毁方法- (void)dealloc&#123; AudioComponentInstanceDispose(_outInstance);&#125;#pragma mark -- 对外API（控制是否捕捉音频数据）- (void)startRunning&#123; AudioOutputUnitStart(_outInstance);&#125;-(void)stopRunning&#123; AudioOutputUnitStop(_outInstance);&#125;#pragma mark -- 对外API（设置捕获音频数据配置项）- (void)setConfig:(BBAudioConfig *)config&#123; _config &#x3D; config; [self private_setupAudioSession];&#125;#pragma mark -- 私有API（初始化音频会话）- (void)private_setupAudioSession&#123; &#x2F;&#x2F;0.初始化编码器 self.encoder &#x3D; [[BBAudioHardEncoder alloc] init]; self.encoder.config &#x3D; self.config; &#x2F;&#x2F;1.获取音频会话实例 self.session &#x3D; [AVAudioSession sharedInstance]; NSError *error &#x3D; nil; [self.session setCategory:AVAudioSessionCategoryPlayAndRecord withOptions:AVAudioSessionCategoryOptionMixWithOthers | AVAudioSessionCategoryOptionDefaultToSpeaker error:&amp;error]; if (error) &#123; NSLog(@&quot;AVAudioSession setupError&quot;); error &#x3D; nil; return; &#125; &#x2F;&#x2F;2.激活会话 [self.session setActive:YES error:&amp;error]; if (error) &#123; NSLog(@&quot;AVAudioSession setActiveError&quot;); error &#x3D; nil; return; &#125; &#x2F;&#x2F;3.设置模式 [self.session setMode:AVAudioSessionModeVideoRecording error:&amp;error]; if (error) &#123; NSLog(@&quot;AVAudioSession setModeError&quot;); error &#x3D; nil; return; &#125; &#x2F;&#x2F;4.设置音频单元 AudioComponentDescription acd &#x3D; &#123; .componentType &#x3D; kAudioUnitType_Output, .componentSubType &#x3D; kAudioUnitSubType_RemoteIO, .componentManufacturer &#x3D; kAudioUnitManufacturer_Apple, .componentFlags &#x3D; 0, .componentFlagsMask &#x3D; 0, &#125;; &#x2F;&#x2F;5.查找音频单元 self.component &#x3D; AudioComponentFindNext(NULL, &amp;acd); &#x2F;&#x2F;6.获取音频单元实例 OSStatus status &#x3D; AudioComponentInstanceNew(self.component, &amp;_outInstance); if (status !&#x3D; noErr) &#123; NSLog(@&quot;AudioSource new AudioComponent error&quot;); status &#x3D; noErr; return; &#125; &#x2F;&#x2F;7.设置音频单元属性--&gt;可读写 0--&gt;不可读写 1--&gt;可读写 UInt32 flagOne &#x3D; 1; AudioUnitSetProperty(_outInstance, kAudioOutputUnitProperty_EnableIO, kAudioUnitScope_Input, 1, &amp;flagOne, sizeof(flagOne)); &#x2F;&#x2F;8.设置音频单元属性--&gt;音频流 AudioStreamBasicDescription asbd &#x3D; &#123;0&#125;; asbd.mSampleRate &#x3D; self.config.sampleRate;&#x2F;&#x2F;采样率 asbd.mFormatID &#x3D; kAudioFormatLinearPCM;&#x2F;&#x2F;原始数据为PCM格式 asbd.mFormatFlags &#x3D; kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked; asbd.mChannelsPerFrame &#x3D; (UInt32)self.config.channels;&#x2F;&#x2F;每帧的声道数量 asbd.mFramesPerPacket &#x3D; 1;&#x2F;&#x2F;每个数据包多少帧 asbd.mBitsPerChannel &#x3D; 16;&#x2F;&#x2F;16位 asbd.mBytesPerFrame &#x3D; asbd.mChannelsPerFrame * asbd.mBitsPerChannel &#x2F; 8;&#x2F;&#x2F;每帧多少字节 bytes -&gt; bit &#x2F; 8 asbd.mBytesPerPacket &#x3D; asbd.mFramesPerPacket * asbd.mBytesPerFrame;&#x2F;&#x2F;每个包多少字节 status &#x3D; AudioUnitSetProperty(_outInstance, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, 1, &amp;asbd, sizeof(asbd)); if (status !&#x3D; noErr) &#123; NSLog(@&quot;AudioUnitSetProperty StreamFormat error&quot;); status &#x3D; noErr; return; &#125; &#x2F;&#x2F;9.设置回调函数 AURenderCallbackStruct cb; cb.inputProcRefCon &#x3D; (__bridge void *)self; cb.inputProc &#x3D; audioBufferCallBack; status &#x3D; AudioUnitSetProperty(_outInstance, kAudioOutputUnitProperty_SetInputCallback, kAudioUnitScope_Global, 1, &amp;cb, sizeof(cb)); if(status !&#x3D; noErr)&#123; NSLog(@&quot;AudioUnitSetProperty StreamFormat InputCallback error&quot;); status &#x3D; noErr; return; &#125; &#x2F;&#x2F;10.初始化音频单元 status &#x3D; AudioUnitInitialize(_outInstance); if (status !&#x3D; noErr) &#123; NSLog(@&quot;AudioUnitInitialize error&quot;); status &#x3D; noErr; return; &#125; &#x2F;&#x2F;11.设置优先采样率 [self.session setPreferredSampleRate:self.config.sampleRate error:&amp;error]; if (error) &#123; NSLog(@&quot;AudioSource setPreferredSampleRate error&quot;); error &#x3D; nil; return; &#125; &#x2F;&#x2F;12.aac文件夹地址 NSString *audioPath &#x3D; [[NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES) lastObject] stringByAppendingPathComponent:@&quot;test.aac&quot;]; [[NSFileManager defaultManager] removeItemAtPath:audioPath error:nil]; [[NSFileManager defaultManager] createFileAtPath:audioPath contents:nil attributes:nil]; self.handle &#x3D; [NSFileHandle fileHandleForWritingAtPath:audioPath];&#125;#pragma mark -- 音频流回调函数static OSStatus audioBufferCallBack(void *inRefCon,AudioUnitRenderActionFlags *ioActionFlags,const AudioTimeStamp *inTimeStamp,UInt32 inBusNumber,UInt32 inNumberFrames,AudioBufferList *ioData) &#123; @autoreleasepool &#123; BBAudioCapture *capture &#x3D; (__bridge BBAudioCapture *)inRefCon; if(!capture) return -1; AudioBuffer buffer; buffer.mData &#x3D; NULL; buffer.mDataByteSize &#x3D; 0; buffer.mNumberChannels &#x3D; 1; AudioBufferList buffers; buffers.mNumberBuffers &#x3D; 1; buffers.mBuffers[0] &#x3D; buffer; OSStatus status &#x3D; AudioUnitRender(capture-&gt;_outInstance, ioActionFlags, inTimeStamp, inBusNumber, inNumberFrames, &amp;buffers); if(status &#x3D;&#x3D; noErr) &#123; [capture.encoder encodeWithBufferList:buffers completianBlock:^(NSData *encodedData, NSError *error) &#123; if (error) &#123; NSLog(@&quot;error:%@&quot;,error); return; &#125; NSLog(@&quot;write to file!&quot;); [capture.handle writeData:encodedData]; &#125;]; &#125; return status; &#125;&#125;@end 2、编码代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#import &quot;BBAudioHardEncoder.h&quot;#import &quot;BBAudioConfig.h&quot;@interface BBAudioHardEncoder ()@property (nonatomic, assign) AudioConverterRef converterRef;@end@implementation BBAudioHardEncoder- (AudioConverterRef)converterRef&#123; if (_converterRef &#x3D;&#x3D; nil) &#123; [self private_setupAudioConvert]; &#125; return _converterRef;&#125;- (void)dealloc &#123; AudioConverterDispose(_converterRef);&#125;- (void)private_setupAudioConvert&#123; &#x2F;&#x2F;1.输入流 AudioStreamBasicDescription inputFormat &#x3D; &#123;0&#125;; inputFormat.mSampleRate &#x3D; self.config.sampleRate;&#x2F;&#x2F;采样率 inputFormat.mFormatID &#x3D; kAudioFormatLinearPCM;&#x2F;&#x2F;PCM采样 inputFormat.mFormatFlags &#x3D; kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked; inputFormat.mChannelsPerFrame &#x3D; (UInt32)self.config.channels;&#x2F;&#x2F;每帧声道数 inputFormat.mFramesPerPacket &#x3D; 1;&#x2F;&#x2F;每包帧数 inputFormat.mBitsPerChannel &#x3D; 16;&#x2F;&#x2F;每声道位数 inputFormat.mBytesPerFrame &#x3D; inputFormat.mBitsPerChannel &#x2F; 8 * inputFormat.mChannelsPerFrame;&#x2F;&#x2F;每帧的字节数 inputFormat.mBytesPerPacket &#x3D; inputFormat.mBytesPerFrame * inputFormat.mFramesPerPacket;&#x2F;&#x2F;每包字节数 &#x2F;&#x2F;2.输出流 AudioStreamBasicDescription outputFormat; &#x2F;&#x2F;2.1初始清零 memset(&amp;outputFormat, 0, sizeof(outputFormat)); &#x2F;&#x2F;2.2音频流，在正常播放情况下的帧率。如果是压缩的格式，这个属性表示解压缩后的帧率。帧率不能为0。 outputFormat.mSampleRate &#x3D; inputFormat.mSampleRate; &#x2F;&#x2F;2.3AAC编码 kAudioFormatMPEG4AAC kAudioFormatMPEG4AAC_HE_V2 outputFormat.mFormatID &#x3D; kAudioFormatMPEG4AAC; &#x2F;&#x2F;2.4无损编码，0则无 outputFormat.mFormatFlags &#x3D; kMPEG4Object_AAC_LC; &#x2F;&#x2F;2.5每一个packet的音频数据大小。如果的动态大小设置为0。动态大小的格式需要用AudioStreamPacketDescription来确定每个packet的大小。 outputFormat.mBytesPerPacket &#x3D; 0; &#x2F;&#x2F;2.6每帧的声道数 outputFormat.mChannelsPerFrame &#x3D; (UInt32)self.config.channels; &#x2F;&#x2F;2.7每个packet的帧数。如果是未压缩的音频数据，值是1。动态帧率格式，这个值是一个较大的固定数字，比如说AAC的1024。如果是动态大小帧数（比如Ogg格式）设置为0。 outputFormat.mFramesPerPacket &#x3D; 1024; &#x2F;&#x2F;2.8每帧的bytes数，每帧的大小。每一帧的起始点到下一帧的起始点。如果是压缩格式，设置为0 。 outputFormat.mBytesPerFrame &#x3D; 0; &#x2F;&#x2F;2.9语音每采样点占用位数 压缩格式设置为0 outputFormat.mBitsPerChannel &#x3D; 0; &#x2F;&#x2F;2.10字节对齐，填0. outputFormat.mReserved &#x3D; 0; &#x2F;&#x2F;3.编码器参数 const OSType subtype &#x3D; kAudioFormatMPEG4AAC; AudioClassDescription requestedCodecs[2] &#x3D; &#123; &#123; kAudioEncoderComponentType, subtype, kAppleSoftwareAudioCodecManufacturer &#125;, &#123; kAudioEncoderComponentType, subtype, kAppleHardwareAudioCodecManufacturer &#125; &#125;; &#x2F;&#x2F;4.编码器 OSStatus result &#x3D; AudioConverterNewSpecific(&amp;inputFormat, &amp;outputFormat, 2, requestedCodecs, &amp;_converterRef); if (result &#x3D;&#x3D; noErr) &#123; NSLog(@&quot;creat convert success!&quot;); &#125;else&#123; NSLog(@&quot;creat convert error!&quot;); _converterRef &#x3D; nil; &#125;&#125;- (void)encodeWithBufferList:(AudioBufferList)bufferList completianBlock:(void (^)(NSData *encodedData, NSError *error))completionBlock&#123; if (!self.converterRef) &#123; return; &#125; int size &#x3D; bufferList.mBuffers[0].mDataByteSize; if (size &lt;&#x3D; 0) &#123; return; &#125; char *aacBuf &#x3D; malloc(size); &#x2F;&#x2F;1.初始化一个输出缓冲列表 AudioBufferList outBufferList; outBufferList.mNumberBuffers &#x3D; 1; outBufferList.mBuffers[0].mNumberChannels &#x3D; bufferList.mBuffers[0].mNumberChannels; outBufferList.mBuffers[0].mDataByteSize &#x3D; bufferList.mBuffers[0].mDataByteSize; &#x2F;&#x2F; 设置缓冲区大小 outBufferList.mBuffers[0].mData &#x3D; aacBuf; &#x2F;&#x2F; 设置AAC缓冲区 UInt32 outputDataPacketSize &#x3D; 1; NSData *data &#x3D; nil; NSError *error &#x3D; nil; OSStatus status &#x3D; AudioConverterFillComplexBuffer(_converterRef, inputDataProc, &amp;bufferList, &amp;outputDataPacketSize, &amp;outBufferList, NULL); if (status &#x3D;&#x3D; 0)&#123; NSData *rawAAC &#x3D; [NSData dataWithBytes:outBufferList.mBuffers[0].mData length:outBufferList.mBuffers[0].mDataByteSize]; NSData *adtsHeader &#x3D; [self getADTSDataWithPacketLength:rawAAC.length]; NSMutableData *fullData &#x3D; [NSMutableData dataWithData:adtsHeader]; [fullData appendData:rawAAC]; data &#x3D; fullData; &#125;else&#123; error &#x3D; [NSError errorWithDomain:NSOSStatusErrorDomain code:status userInfo:nil]; NSLog(@&quot;音频编码失败&quot;); return; &#125; if (completionBlock) &#123; dispatch_async(dispatch_get_global_queue(0, 0), ^&#123; completionBlock(data, error); &#125;); &#125; free(aacBuf);&#125;#pragma mark -- AudioCallBackOSStatus inputDataProc(AudioConverterRef inConverter, UInt32 *ioNumberDataPackets, AudioBufferList *ioData,AudioStreamPacketDescription **outDataPacketDescription, void *inUserData) &#123; &#x2F;&#x2F;填充PCM到缓冲区 AudioBufferList bufferList &#x3D; *(AudioBufferList*)inUserData; ioData-&gt;mBuffers[0].mNumberChannels &#x3D; 1; ioData-&gt;mBuffers[0].mData &#x3D; bufferList.mBuffers[0].mData; ioData-&gt;mBuffers[0].mDataByteSize &#x3D; bufferList.mBuffers[0].mDataByteSize; ioData-&gt;mNumberBuffers &#x3D; 1; return noErr;&#125;&#x2F;*** Add ADTS header at the beginning of each and every AAC packet.* This is needed as MediaCodec encoder generates a packet of raw* AAC data.** Note the packetLen must count in the ADTS header itself.* See: http:&#x2F;&#x2F;wiki.multimedia.cx&#x2F;index.php?title&#x3D;ADTS* Also: http:&#x2F;&#x2F;wiki.multimedia.cx&#x2F;index.php?title&#x3D;MPEG-4_Audio#Channel_Configurations**&#x2F;- (NSData *)getADTSDataWithPacketLength:(NSInteger)packetLength &#123; int adtsLength &#x3D; 7; char *packet &#x3D; malloc(sizeof(char) * adtsLength); &#x2F;&#x2F; Variables Recycled by addADTStoPacket int profile &#x3D; 2; &#x2F;&#x2F;AAC LC &#x2F;&#x2F;39&#x3D;MediaCodecInfo.CodecProfileLevel.AACObjectELD; int freqIdx &#x3D; 4; &#x2F;&#x2F;44.1KHz int chanCfg &#x3D; 1; &#x2F;&#x2F;MPEG-4 Audio Channel Configuration. 1 Channel front-center NSUInteger fullLength &#x3D; adtsLength + packetLength; &#x2F;&#x2F; fill in ADTS data packet[0] &#x3D; (char)0xFF; &#x2F;&#x2F; 11111111 &#x3D; syncword packet[1] &#x3D; (char)0xF9; &#x2F;&#x2F; 1111 1 00 1 &#x3D; syncword MPEG-2 Layer CRC packet[2] &#x3D; (char)(((profile-1)&lt;&lt;6) + (freqIdx&lt;&lt;2) +(chanCfg&gt;&gt;2)); packet[3] &#x3D; (char)(((chanCfg&amp;3)&lt;&lt;6) + (fullLength&gt;&gt;11)); packet[4] &#x3D; (char)((fullLength&amp;0x7FF) &gt;&gt; 3); packet[5] &#x3D; (char)(((fullLength&amp;7)&lt;&lt;5) + 0x1F); packet[6] &#x3D; (char)0xFC; NSData *data &#x3D; [NSData dataWithBytesNoCopy:packet length:adtsLength freeWhenDone:YES]; return data;&#125;@end 以上代码为主要代码，配置代码无非就是采样率：44.1kHz，声道：双声道。完整代码地址：https://github.com/ibabyblue/PCMHardEncodeToAAC将编码的AAC数据写入本地文件，利用VLC播放器可以直接播放.aac格式文件，测试很方便。 写在最后，一路学习，坎坷良多，非常感谢无私分享的开发者们，感谢Jovins、iossigner分享的干货，感恩！参考地址：http://blog.csdn.net/ownwell/article/details/8114121/https://wiki.multimedia.cx/index.php?title=ADTShttps://developer.apple.com/documentation/audiotoolbox/audio_converter_services?language=objc","categories":[{"name":"iOS音视频技术","slug":"iOS音视频技术","permalink":"http://yoursite.com/categories/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"}]},{"title":"iOS音视频开发-视频软编码-FFmpeg-x264编码H264文件","slug":"iOS音视频开发-视频软编码-FFmpeg-x264编码H264文件","date":"2018-02-22T07:02:03.000Z","updated":"2020-04-10T07:18:11.954Z","comments":true,"path":"2018/02/22/iOS音视频开发-视频软编码-FFmpeg-x264编码H264文件/","link":"","permalink":"http://yoursite.com/2018/02/22/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91-%E8%A7%86%E9%A2%91%E8%BD%AF%E7%BC%96%E7%A0%81-FFmpeg-x264%E7%BC%96%E7%A0%81H264%E6%96%87%E4%BB%B6/","excerpt":"","text":"上篇记录了利用x264编码的实现，这里记录一下FFmpeg+x264编码为H.264的实现过程，为什么使用FFmpeg+x264，因为两种框架互补组成了强大的编解码器（FFmpeg解码，x246编码）。 编译FFmpeg+x264FFmpeg地址：https://github.com/FFmpeg/FFmpeg编译脚本：https://github.com/kewlbear/FFmpeg-iOS-build-scriptx264地址：http://www.videolan.org/developers/x264.html编译脚本：https://github.com/kewlbear/x264-ios具体编译过程：x264的编译过程在上篇iOS音视频开发-视频软编码(x264编码H.264文件)FFmpeg+x264编译步骤： 1、将编译好的x264文件夹放置在FFmpeg脚本目录下，并将文件夹改名为fat-x264(因为脚本中定义的引用x264文件夹的名称为fat-x264); 2、执行脚本文件：./build-ffmpeg.sh。这里需要注意的问题，之前编译并没有遇到，此次总结重新编译了一次，遇到一些问题记录一下。 1）现阶段最新的FFmpeg版本为：n3.4.2，脚本中使用版本号为：n3.4。执行脚本的时候会出现诸如此类的错误： 123libavcodec&#x2F;libx264.c: In function &#39;x264_init_static&#39;:libavcodec&#x2F;libx264.c:892.9 error: &#39;x264_bit_depth&#39; undeclared(first use in this function)if(x264_bit_depth&#x3D;&#x3D; 8) 解决办法：修改脚本文件中的版本号：FF_VERSION=”3.4-&gt;FF_VERSION=”3.4.2”。 2）要将x264编译进FFmpeg中，需要取消脚本中对该句代码的注销： 1#X264&#x3D;&#96;pwd&#96;&#x2F;fat-x264 -&gt;X264&#x3D;&#96;pwd&#96;&#x2F;fat-x264 3）关于bitcode，现阶段在编译库文件的时候，支持bitcode还是有必要的（毕竟某个工程因为使用了此编译库文件放弃bitcode功能，向上层开发者提供了功能，是不使用是他们的事了），脚本中已经实现了支持bitcode功能，不必修改。 4）将编译好的文件拖拽到工程中，需要添加的依赖库为：libiconv.dylib、libz.dylib/libbz2.dylib、CoreMedia.framework、AVFoundation.framework、VideoToolbox.framework，不然会报并未支持arm64……架构的错误。命令行命令： 1234&#x2F;&#x2F;查看是否支持相应的架构：arm64 i386....lipo -info libxx.a&#x2F;&#x2F;查看是够支持bitcode &gt;&#x3D;0otool -l libx264.a | grep __bitcode | wc -l 介绍：不错的编译过程文章视频捕获和编码配置代码在前面已记录，这里就不赘述了。FFmpeg+x264编码实现代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305#import &lt;Foundation&#x2F;Foundation.h&gt;#import &lt;CoreMedia&#x2F;CoreMedia.h&gt;@class BBVideoConfig;@interface BBH264SoftEncoder : NSObject&#x2F;** 设置编码后文件的保存路径*&#x2F;- (void)setFilePath:(NSString *)path;&#x2F;** 初始化编码配置*&#x2F;- (void)setupEncodeWithConfig:(BBVideoConfig *)config;&#x2F;** 将CMSampleBufferRef格式的数据编码成h264并写入文件*&#x2F;- (void)encoderToH264:(CMSampleBufferRef)sampleBuffer;&#x2F;** 释放资源*&#x2F;- (void)freeX264Resource;@end#import &quot;BBH264SoftEncoder.h&quot;#import &quot;BBVideoConfig.h&quot;#ifdef __cplusplusextern &quot;C&quot; &#123;#endif#include &lt;libavutil&#x2F;opt.h&gt;#include &lt;libavutil&#x2F;imgutils.h&gt;#include &lt;libavcodec&#x2F;avcodec.h&gt;#include &lt;libavformat&#x2F;avformat.h&gt;#include &lt;libswscale&#x2F;swscale.h&gt;#ifdef __cplusplus&#125;;#endif@implementation BBH264SoftEncoder&#123; AVFormatContext *pFormatCtx; AVOutputFormat *fmt; AVStream *video_st; AVCodecContext *pCodecCtx; AVCodec *pCodec; AVPacket pkt; uint8_t *picture_buf; AVFrame *pFrame; int picture_size; int y_size; int framecnt; char *out_file; int encoder_h264_frame_width; &#x2F;&#x2F; 编码的图像宽度 int encoder_h264_frame_height; &#x2F;&#x2F; 编码的图像高度&#125;&#x2F;** 设置编码后文件的文件名，保存路径*&#x2F;- (void)setFilePath:(NSString *)path;&#123; out_file &#x3D; [self nsstring2char:path];&#125;&#x2F;** 将路径转成C语言字符串(传入路径为C字符串)*&#x2F;- (char*)nsstring2char:(NSString *)path&#123; NSUInteger len &#x3D; [path length]; char *filepath &#x3D; (char*)malloc(sizeof(char) * (len + 1)); [path getCString:filepath maxLength:len + 1 encoding:[NSString defaultCStringEncoding]]; return filepath;&#125;&#x2F;** 设置X264*&#x2F;- (void)setupEncodeWithConfig:(BBVideoConfig *)config&#123; &#x2F;&#x2F; 1.默认从第0帧开始(记录当前的帧数) framecnt &#x3D; 0; &#x2F;&#x2F; 2.记录传入的宽度&amp;高度 encoder_h264_frame_width &#x3D; config.videoSize.width; encoder_h264_frame_height &#x3D; config.videoSize.height; &#x2F;&#x2F; 3.注册FFmpeg所有编解码器(无论编码还是解码都需要该步骤) av_register_all(); &#x2F;&#x2F; 4.初始化AVFormatContext: 用作之后写入视频帧并编码成 h264，贯穿整个工程当中(释放资源时需要销毁) pFormatCtx &#x3D; avformat_alloc_context(); &#x2F;&#x2F; 5.设置输出文件的路径，fmt初始化的时候根据传入的参数猜出video_codec、mime_type、extensions等等信息。 fmt &#x3D; av_guess_format(NULL, out_file, NULL); pFormatCtx-&gt;oformat &#x3D; fmt; &#x2F;&#x2F; 6.打开文件的缓冲区输入输出，flags 标识为 AVIO_FLAG_READ_WRITE ，可读写 if (avio_open(&amp;pFormatCtx-&gt;pb, out_file, AVIO_FLAG_READ_WRITE) &lt; 0)&#123; printf(&quot;Failed to open output file! \\n&quot;); &#125; &#x2F;&#x2F; 7.创建新的输出流, 用于写入文件 video_st &#x3D; avformat_new_stream(pFormatCtx, 0); if (video_st&#x3D;&#x3D;NULL)&#123; printf(&quot;Failed to setup stream! \\n&quot;); return; &#125; &#x2F;&#x2F; 8.pCodecCtx 用户存储编码所需的参数格式等等 &#x2F;&#x2F; 8.1.从媒体流中获取到编码结构体，他们是一一对应的关系，一个 AVStream 对应一个 AVCodecContext AVCodec *codec &#x3D; avcodec_find_encoder(pFormatCtx-&gt;oformat-&gt;video_codec); pCodecCtx &#x3D; avcodec_alloc_context3(codec); &#x2F;&#x2F; 8.2.设置编码器的编码格式(是一个id)，每一个编码器都对应着自己的 id，例如 h264 的编码 id 就是 AV_CODEC_ID_H264 pCodecCtx-&gt;codec_id &#x3D; fmt-&gt;video_codec; &#x2F;&#x2F; 8.3.设置编码类型为 视频编码 pCodecCtx-&gt;codec_type &#x3D; AVMEDIA_TYPE_VIDEO; &#x2F;&#x2F; 8.4.设置像素格式为 yuv 格式 pCodecCtx-&gt;pix_fmt &#x3D; AV_PIX_FMT_YUV420P; &#x2F;&#x2F; 8.5.设置视频的宽高 pCodecCtx-&gt;width &#x3D; encoder_h264_frame_width; pCodecCtx-&gt;height &#x3D; encoder_h264_frame_height; &#x2F;&#x2F; 8.6.设置帧率 pCodecCtx-&gt;time_base.num &#x3D; 1; pCodecCtx-&gt;time_base.den &#x3D; 25; &#x2F;&#x2F; 8.7.设置码率（比特率） pCodecCtx-&gt;bit_rate &#x3D; config.bitrate; &#x2F;&#x2F; 8.8.视频质量度量标准(常见qmin&#x3D;10, qmax&#x3D;51) pCodecCtx-&gt;qmin &#x3D; 10; pCodecCtx-&gt;qmax &#x3D; 51; &#x2F;&#x2F; 8.9.设置图像组层的大小(GOP--&gt;两个I帧之间的间隔) pCodecCtx-&gt;gop_size &#x3D; 30; &#x2F;&#x2F; 8.10.设置 B 帧最大的数量，B帧为视频图片空间的前后预测帧， B 帧相对于 I、P 帧来说，压缩率比较大，也就是说相同码率的情况下， &#x2F;&#x2F; 越多 B 帧的视频，越清晰，现在很多打视频网站的高清视频，就是采用多编码 B 帧去提高清晰度， &#x2F;&#x2F; 但同时对于编解码的复杂度比较高，比较消耗性能与时间 pCodecCtx-&gt;max_b_frames &#x3D; 5; &#x2F;&#x2F; 9.可选设置 AVDictionary *param &#x3D; 0; &#x2F;&#x2F; H.264 if(pCodecCtx-&gt;codec_id &#x3D;&#x3D; AV_CODEC_ID_H264) &#123; &#x2F;&#x2F; 通过--preset的参数调节编码速度和质量的平衡。 av_dict_set(&amp;param, &quot;preset&quot;, &quot;slow&quot;, 0); &#x2F;&#x2F; 通过--tune的参数值指定片子的类型，是和视觉优化的参数，或有特别的情况。 &#x2F;&#x2F; zerolatency: 零延迟，用在需要非常低的延迟的情况下，比如视频直播的编码 av_dict_set(&amp;param, &quot;tune&quot;, &quot;zerolatency&quot;, 0); &#125; &#x2F;&#x2F; 10.输出打印信息，内部是通过printf函数输出（不需要输出可以注释掉） av_dump_format(pFormatCtx, 0, out_file, 1); &#x2F;&#x2F; 11.通过 codec_id 找到对应的编码器 pCodec &#x3D; avcodec_find_encoder(pCodecCtx-&gt;codec_id); if (!pCodec) &#123; printf(&quot;Can not find encoder! \\n&quot;); &#125; &#x2F;&#x2F; 12.打开编码器，并设置参数 param if (avcodec_open2(pCodecCtx, pCodec,&amp;param) &lt; 0) &#123; printf(&quot;Failed to open encoder! \\n&quot;); &#125; &#x2F;&#x2F; 13.将AVCodecContext的成员复制到AVCodecParameters结构体 avcodec_parameters_from_context(video_st-&gt;codecpar, pCodecCtx); &#x2F;&#x2F; 14.真实帧率 AVRational rational &#x3D; &#123;1, 25&#125;; av_stream_set_r_frame_rate(video_st, rational); &#x2F;&#x2F; 15.初始化原始数据对象: AVFrame pFrame &#x3D; av_frame_alloc(); &#x2F;&#x2F; 16.通过像素格式(这里为 YUV)获取图片的真实大小，例如将 480 * 720 转换成 int 类型 av_image_fill_arrays(pFrame-&gt;data, pFrame-&gt;linesize, picture_buf, pCodecCtx-&gt;pix_fmt, pCodecCtx-&gt;width, pCodecCtx-&gt;height, 1); &#x2F;&#x2F; 17.h264 封装格式的文件头部，基本上每种编码都有着自己的格式的头部。 if (avformat_write_header(pFormatCtx, NULL) &lt; 0) &#123; printf(&quot;Failed to write! \\n&quot;); return; &#125; &#x2F;&#x2F; 18.创建编码后的数据 AVPacket 结构体来存储 AVFrame 编码后生成的数据 av_new_packet(&amp;pkt, picture_size); &#x2F;&#x2F; 19.设置 yuv 数据中 y 图的宽高 y_size &#x3D; pCodecCtx-&gt;width * pCodecCtx-&gt;height;&#125;&#x2F;** 将CMSampleBufferRef格式的数据编码成h264并写入文件**&#x2F;- (void)encoderToH264:(CMSampleBufferRef)sampleBuffer&#123; &#x2F;&#x2F; 1.通过CMSampleBufferRef对象获取CVPixelBufferRef对象 CVPixelBufferRef imageBuffer &#x3D; CMSampleBufferGetImageBuffer(sampleBuffer); &#x2F;&#x2F; 2.锁定imageBuffer内存地址开始进行编码 if (CVPixelBufferLockBaseAddress(imageBuffer, 0) &#x3D;&#x3D; kCVReturnSuccess) &#123; &#x2F;&#x2F; 3.从CVPixelBufferRef读取YUV的值 &#x2F;&#x2F; NV12和NV21属于YUV格式，是一种two-plane模式，即Y和UV分为两个Plane，但是UV（CbCr）为交错存储，而不是分为三个plane &#x2F;&#x2F; 3.1.获取Y分量的地址 UInt8 *bufferPtr &#x3D; (UInt8 *)CVPixelBufferGetBaseAddressOfPlane(imageBuffer,0); &#x2F;&#x2F; 3.2.获取UV分量的地址 UInt8 *bufferPtr1 &#x3D; (UInt8 *)CVPixelBufferGetBaseAddressOfPlane(imageBuffer,1); &#x2F;&#x2F; 3.3.根据像素获取图片的真实宽度&amp;高度 size_t width &#x3D; CVPixelBufferGetWidth(imageBuffer); size_t height &#x3D; CVPixelBufferGetHeight(imageBuffer); &#x2F;&#x2F; 获取Y分量长度 size_t bytesrow0 &#x3D; CVPixelBufferGetBytesPerRowOfPlane(imageBuffer,0); size_t bytesrow1 &#x3D; CVPixelBufferGetBytesPerRowOfPlane(imageBuffer,1); UInt8 *yuv420_data &#x3D; (UInt8 *)malloc(width * height * 3 &#x2F; 2); &#x2F;&#x2F; 3.4.将NV12数据转成YUV420P(I420)数据 UInt8 *pY &#x3D; bufferPtr; UInt8 *pUV &#x3D; bufferPtr1; UInt8 *pU &#x3D; yuv420_data + width * height; UInt8 *pV &#x3D; pU + width * height &#x2F; 4; for(int i &#x3D;0;i&lt;height;i++) &#123; memcpy(yuv420_data+i*width,pY+i*bytesrow0,width); &#125; for(int j &#x3D; 0;j&lt;height&#x2F;2;j++) &#123; for(int i &#x3D;0;i&lt;width&#x2F;2;i++) &#123; *(pU++) &#x3D; pUV[i&lt;&lt;1]; *(pV++) &#x3D; pUV[(i&lt;&lt;1) + 1]; &#125; pUV +&#x3D; bytesrow1; &#125; &#x2F;&#x2F; 3.5.分别读取YUV的数据 picture_buf &#x3D; yuv420_data; pFrame-&gt;data[0] &#x3D; picture_buf; &#x2F;&#x2F; Y pFrame-&gt;data[1] &#x3D; picture_buf + y_size; &#x2F;&#x2F; U pFrame-&gt;data[2] &#x3D; picture_buf + y_size * 5 &#x2F; 4; &#x2F;&#x2F; V &#x2F;&#x2F; 4.设置当前帧 pFrame-&gt;pts &#x3D; framecnt; &#x2F;&#x2F; 4.设置宽度高度以及YUV格式 pFrame-&gt;width &#x3D; encoder_h264_frame_width; pFrame-&gt;height &#x3D; encoder_h264_frame_height; pFrame-&gt;format &#x3D; AV_PIX_FMT_YUV420P; &#x2F;&#x2F; 5.对编码前的原始数据(AVFormat)利用编码器进行编码，将 pFrame 编码后的数据传入pkt 中 int ret &#x3D; avcodec_send_frame(pCodecCtx, pFrame); if (ret !&#x3D; 0) &#123; printf(&quot;Failed to encode! \\n&quot;); return; &#125; while (avcodec_receive_packet(pCodecCtx, &amp;pkt) &#x3D;&#x3D; 0) &#123; framecnt++; pkt.stream_index &#x3D; video_st-&gt;index; &#x2F;&#x2F;也可以使用C语言函数：fwrite()、fflush()写文件和清空文件写入缓冲区。 ret &#x3D; av_write_frame(pFormatCtx, &amp;pkt); if (ret &lt; 0) &#123; printf(&quot;Failed write to file！\\n&quot;); &#125; &#x2F;&#x2F;释放packet av_packet_unref(&amp;pkt); &#125; &#x2F;&#x2F; 7.释放yuv数据 free(yuv420_data); &#125; CVPixelBufferUnlockBaseAddress(imageBuffer, 0);&#125;&#x2F;** 释放资源*&#x2F;- (void)freeX264Resource&#123; &#x2F;&#x2F; 1.将还未输出的AVPacket输出出来 av_write_trailer(pFormatCtx); &#x2F;&#x2F; 2.关闭资源 avcodec_close(pCodecCtx); av_free(pFrame); avio_close(pFormatCtx-&gt;pb); avformat_free_context(pFormatCtx);&#125;@end 编码使用FFmpeg新版API实现，网上很多都是较旧的API代码，但不影响，只是个别接口变更而已，整体的实现思路一致。学习过程中，查阅了大量的资料，收获颇丰，非常感谢学习路上各位coder的无私分享，尤其coderWhy先森、七牛的深爱、雷霄骅（致敬）。参考链接：https://depthlove.github.io/2015/09/18/use-ffmpeg-and-x264-encode-iOS-camera-video-to-h264/http://blog.csdn.net/leixiaohua1020/article/details/25430425","categories":[{"name":"iOS音视频技术","slug":"iOS音视频技术","permalink":"http://yoursite.com/categories/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"}]},{"title":"iOS音视频开发-视频软编码的实现-x264","slug":"iOS音视频开发-视频软编码的实现-x264","date":"2018-02-11T06:52:45.000Z","updated":"2020-04-10T07:18:17.799Z","comments":true,"path":"2018/02/11/iOS音视频开发-视频软编码的实现-x264/","link":"","permalink":"http://yoursite.com/2018/02/11/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91-%E8%A7%86%E9%A2%91%E8%BD%AF%E7%BC%96%E7%A0%81%E7%9A%84%E5%AE%9E%E7%8E%B0-x264/","excerpt":"","text":"视频软编码：软编码主要是利用CPU编码的过程，通常为FFmpeg+x264。 FFmpegFFmpeg是一个非常强大的音视频处理库,包括视频采集功能、视频格式转换、视频抓图、给视频加水印等。FFmpeg在Linux平台下开发，但它同样也可以在其它操作系统环境中编译运行，包括Windows、Mac OS X等。x264H.264是ITU制定的视频编码标准而x264是一个开源的H.264/MPEG-4 AVC视频编码函数库，是最好的有损视频编码器,里面集成了非常多优秀的算法用于视频编码.x264官网PS:FFmpeg本身并不包含编码器，但存在强大的解码器，而x264只提供了强大的编码器，但是其独立存在，社区提供了将x264编译进FFmpeg的方法，所以开发时使用的为FFmpeg+x264。这里记录x264编码器的使用方法，FFmpeg+x264的使用后续记录。编译x264下载x264源码：https://www.videolan.org/developers/x264.html 下载gas-preprocessor文件：https://github.com/libav/gas-preprocessor。将下载的gas-preprocessor文件拷贝到/usr/local/bin目录下。修改文件权限：chmod 777 /usr/local/bin/gas-preprocessor.pl。 下载x264编译脚本文件：https://github.com/kewlbear/x264-ios将脚本文件build-x264.sh 放在x264源码文件同级目录下，并不是x264文件夹里面。同级目录.png修改权限、执行脚本： sudo chmod u+x build-x264.shsudo ./build-x264.sh当脚本执行过程中可能会出现警告导致不能编译成功，一般为yasm版本过低或者nasm版本过低导致的(我遇到的)。 123Found yasm x.x.x.xxxxMinimum version is yasm-x.x.xIf you really want to compile without asm, configure with --disable-asm. 或者 123Found nasm x.x.x.xxxxMinimum version is nasm-x.x.xIf you really want to compile without asm, configure with --disable-asm. 解决办法：下载Homebrew,利用Homebrew下载yasm/nasm。Homebrew下载安装： 地址：https://brew.sh/Homebrew安装yasm命令：brew install yasmHomebrew安装nasm命令：brew install nasm脚本执行完毕生成的文件：编译好的x264文件夹.png使用命令行工具查看编译好的.a文件支持的架构： 12命令：lipo -info libx264.a结果：Architectures in the fat file: libx264.a are: armv7 armv7s i386 x86_64 arm64 当然执行脚本的时候你可以选择想要的架构： 1234567891011To build everything:&#x2F;&#x2F;支持所有架构.&#x2F;build-x264.shTo build for arm64:&#x2F;&#x2F;只支持arm64.&#x2F;build-x264.sh arm64To build fat library for armv7 and x86_64 (64-bit simulator):&#x2F;&#x2F;只支持armv7和x86_64.&#x2F;build-x264.sh armv7 x86_64To build fat library from separately built thin libraries:&#x2F;&#x2F;支持各架构独立库文件.&#x2F;build-x264.sh lipo x264编码实现将编译好的x264-iOS文件夹拖入工程即可。x264编码参数设置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283- (void)setupEncodeWithConfig:(BBVideoConfig *)config&#123; _config &#x3D; config; pX264Param &#x3D; (x264_param_t *)malloc(sizeof(x264_param_t)); assert(pX264Param); &#x2F;* 配置参数预设置 * 主要是zerolatency该参数，即时编码。 * static const char * const x264_tune_names[] &#x3D; &#123; &quot;film&quot;, &quot;animation&quot;, &quot;grain&quot;, &quot;stillimage&quot;, &quot;psnr&quot;, &quot;ssim&quot;, &quot;fastdecode&quot;, &quot;zerolatency&quot;, 0 &#125;; *&#x2F; x264_param_default_preset(pX264Param, &quot;veryfast&quot;, &quot;zerolatency&quot;); &#x2F;* 设置Profile.使用Baseline profile * static const char * const x264_profile_names[] &#x3D; &#123; &quot;baseline&quot;, &quot;main&quot;, &quot;high&quot;, &quot;high10&quot;, &quot;high422&quot;, &quot;high444&quot;, 0 &#125;; *&#x2F; x264_param_apply_profile(pX264Param, &quot;baseline&quot;); &#x2F;&#x2F; cpuFlags pX264Param-&gt;i_threads &#x3D; X264_SYNC_LOOKAHEAD_AUTO; &#x2F;&#x2F; 取空缓冲区继续使用不死锁的保证 &#x2F;&#x2F; 视频宽高 pX264Param-&gt;i_width &#x3D; config.videoSize.width; &#x2F;&#x2F; 要编码的图像宽度. pX264Param-&gt;i_height &#x3D; config.videoSize.height; &#x2F;&#x2F; 要编码的图像高度 pX264Param-&gt;i_frame_total &#x3D; 0; &#x2F;&#x2F;编码总帧数，未知设置为0 &#x2F;&#x2F; 流参数 pX264Param-&gt;b_cabac &#x3D; 0; &#x2F;&#x2F;支持利用基于上下文的自适应的算术编码 0为不支持 pX264Param-&gt;i_bframe &#x3D; 5;&#x2F;&#x2F;两个参考帧之间B帧的数量 pX264Param-&gt;b_interlaced &#x3D; 0;&#x2F;&#x2F;隔行扫描 pX264Param-&gt;rc.i_rc_method &#x3D; X264_RC_ABR; &#x2F;&#x2F; 码率控制，CQP(恒定质量)，CRF(恒定码率)，ABR(平均码率) pX264Param-&gt;i_level_idc &#x3D; 30; &#x2F;&#x2F; 编码复杂度 &#x2F;&#x2F; 图像质量 pX264Param-&gt;rc.f_rf_constant &#x3D; 15; &#x2F;&#x2F; rc.f_rf_constant是实际质量，越大图像越花，越小越清晰 pX264Param-&gt;rc.f_rf_constant_max &#x3D; 45; &#x2F;&#x2F; param.rc.f_rf_constant_max ，图像质量的最大值。 &#x2F;&#x2F; 速率控制参数 通常为屏幕分辨率*3 （宽x高x3） pX264Param-&gt;rc.i_bitrate &#x3D; config.bitrate &#x2F; 1000; &#x2F;&#x2F; 码率(比特率), x264使用的bitrate需要&#x2F;1000。 &#x2F;&#x2F; pX264Param-&gt;rc.i_vbv_max_bitrate&#x3D;(int)((m_bitRate * 1.2) &#x2F; 1000) ; &#x2F;&#x2F; 平均码率模式下，最大瞬时码率，默认0(与-B设置相同) pX264Param-&gt;rc.i_vbv_buffer_size &#x3D; pX264Param-&gt;rc.i_vbv_max_bitrate &#x3D; (int)((config.bitrate * 1.2) &#x2F; 1000); pX264Param-&gt;rc.f_vbv_buffer_init &#x3D; 0.9;&#x2F;&#x2F;默认0.9 &#x2F;&#x2F; 使用实时视频传输时，需要实时发送sps,pps数据 pX264Param-&gt;b_repeat_headers &#x3D; 1; &#x2F;&#x2F; 重复SPS&#x2F;PPS 放到关键帧前面。该参数设置是让每个I帧都附带sps&#x2F;pps。 &#x2F;&#x2F; 帧率 pX264Param-&gt;i_fps_num &#x3D; config.fps; &#x2F;&#x2F; 帧率分子 pX264Param-&gt;i_fps_den &#x3D; 1; &#x2F;&#x2F; 帧率分母 pX264Param-&gt;i_timebase_den &#x3D; pX264Param-&gt;i_fps_num; pX264Param-&gt;i_timebase_num &#x3D; pX264Param-&gt;i_fps_den; &#x2F;* I帧间隔 GOP * 一般为帧率的整数倍，通常设置2倍，即 GOP &#x3D; 帧率 * 2； *&#x2F; pX264Param-&gt;b_intra_refresh &#x3D; 1; pX264Param-&gt;b_annexb &#x3D; 1; pX264Param-&gt;i_keyint_max &#x3D; config.fps * 2; &#x2F;&#x2F; Log参数，打印编码信息 pX264Param-&gt;i_log_level &#x3D; X264_LOG_DEBUG; &#x2F;&#x2F; 编码需要的辅助变量 iNal &#x3D; 0; pNals &#x3D; NULL; pPicIn &#x3D; (x264_picture_t *)malloc(sizeof(x264_picture_t)); memset(pPicIn, 0, sizeof(x264_picture_t)); x264_picture_alloc(pPicIn, X264_CSP_I420, pX264Param-&gt;i_width, pX264Param-&gt;i_height); pPicIn-&gt;i_type &#x3D; X264_TYPE_AUTO; pPicIn-&gt;img.i_plane &#x3D; 3; pPicOut &#x3D; (x264_picture_t *)malloc(sizeof(x264_picture_t)); memset(pPicOut, 0, sizeof(x264_picture_t)); x264_picture_init(pPicOut); &#x2F;&#x2F; 打开编码器句柄,通过x264_encoder_parameters得到设置给X264 &#x2F;&#x2F; 的参数.通过x264_encoder_reconfig更新X264的参数 pX264Handle &#x3D; x264_encoder_open(pX264Param); assert(pX264Handle);&#125; x264编码主要实现代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576- (void)encoderToH264:(CMSampleBufferRef)sampleBuffer&#123; CVImageBufferRef imageBuffer &#x3D; CMSampleBufferGetImageBuffer(sampleBuffer); CVPixelBufferLockBaseAddress(imageBuffer, 0); UInt8 *bufferPtr &#x3D; (UInt8 *)CVPixelBufferGetBaseAddressOfPlane(imageBuffer,0); UInt8 *bufferPtr1 &#x3D; (UInt8 *)CVPixelBufferGetBaseAddressOfPlane(imageBuffer,1); size_t width &#x3D; CVPixelBufferGetWidth(imageBuffer); size_t height &#x3D; CVPixelBufferGetHeight(imageBuffer); size_t bytesrow0 &#x3D; CVPixelBufferGetBytesPerRowOfPlane(imageBuffer,0); size_t bytesrow1 &#x3D; CVPixelBufferGetBytesPerRowOfPlane(imageBuffer,1); UInt8 *yuv420_data &#x3D; (UInt8 *)malloc(width * height *3&#x2F; 2);&#x2F;&#x2F;buffer to store YUV with layout YYYYYYYYUUVV &#x2F;* convert NV12 data to YUV420*&#x2F; UInt8 *pY &#x3D; bufferPtr ; UInt8 *pUV &#x3D; bufferPtr1; UInt8 *pU &#x3D; yuv420_data + width * height; UInt8 *pV &#x3D; pU + width * height &#x2F; 4; for(int i &#x3D; 0; i &lt; height; i++) &#123; memcpy(yuv420_data + i * width, pY + i * bytesrow0, width); &#125; for(int j &#x3D; 0;j &lt; height&#x2F;2; j++) &#123; for(int i &#x3D; 0; i &lt; width&#x2F;2; i++) &#123; *(pU++) &#x3D; pUV[i&lt;&lt;1]; *(pV++) &#x3D; pUV[(i&lt;&lt;1) + 1]; &#125; pUV +&#x3D; bytesrow1; &#125; &#x2F;&#x2F; yuv420_data &lt;&#x3D;&#x3D;&gt; pInFrame pPicIn-&gt;img.plane[0] &#x3D; yuv420_data; pPicIn-&gt;img.plane[1] &#x3D; pPicIn-&gt;img.plane[0] + (int)_config.videoSize.width * (int)_config.videoSize.height; pPicIn-&gt;img.plane[2] &#x3D; pPicIn-&gt;img.plane[1] + (int)(_config.videoSize.width * _config.videoSize.height &#x2F; 4); pPicIn-&gt;img.i_stride[0] &#x3D; _config.videoSize.width; pPicIn-&gt;img.i_stride[1] &#x3D; _config.videoSize.width &#x2F; 2; pPicIn-&gt;img.i_stride[2] &#x3D; _config.videoSize.width &#x2F; 2; &#x2F;&#x2F; 编码 int frame_size &#x3D; x264_encoder_encode(pX264Handle, &amp;pNals, &amp;iNal, pPicIn, pPicOut); &#x2F;&#x2F; 将编码数据写入文件 if(frame_size &gt; 0) &#123; for (int i &#x3D; 0; i &lt; iNal; ++i) &#123; fwrite(pNals[i].p_payload, 1, pNals[i].i_payload, pFile); &#125; &#125; CVPixelBufferUnlockBaseAddress(imageBuffer, 0);&#125;释放资源：- (void)freeX264Resource&#123; &#x2F;&#x2F; 清除图像区域 x264_picture_clean(pPicIn); &#x2F;&#x2F; 关闭编码器句柄 x264_encoder_close(pX264Handle); pX264Handle &#x3D; NULL; free(pPicIn); pPicIn &#x3D; NULL; free(pPicOut); pPicOut &#x3D; NULL; free(pX264Param); pX264Param &#x3D; NULL; fclose(pFile); pFile &#x3D; NULL;&#125; 代码地址：参考链接：https://www.cnblogs.com/fojian/archive/2012/09/01/2666627.htmlhttps://web.archive.org/web/20150207075004/http://mewiki.project357.com/wiki/X264_Settings","categories":[{"name":"iOS音视频技术","slug":"iOS音视频技术","permalink":"http://yoursite.com/categories/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"}]},{"title":"iOS音视频开发-视频硬编码的实现","slug":"iOS音视频开发-视频硬编码的实现","date":"2018-02-07T06:47:43.000Z","updated":"2020-04-10T07:18:23.167Z","comments":true,"path":"2018/02/07/iOS音视频开发-视频硬编码的实现/","link":"","permalink":"http://yoursite.com/2018/02/07/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91-%E8%A7%86%E9%A2%91%E7%A1%AC%E7%BC%96%E7%A0%81%E7%9A%84%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"视频编码视频编码分为软编码和硬编码： 软编码：1.利用CPU进行大批量的编码计算处理。2.兼容性好。3.耗电量大，手机发烫（很烫，感觉要爆炸了O(∩_∩)O~）硬编码1.利用GPU进行编码处理。2.兼容性略差。3.手机不会很烫。（硬编码需要iOS8及以上版本可以使用，之前并未开发，之前版本只能软编码。）这里记录硬编码的实现，软编码后续会记录。 H264视频编码需要了解的编码格式，H264/AVC为视频编码格式，需要将采集到的视频帧编码为H264格式的数据。H264的特点：1．更高的编码效率：同H.263等标准的特率效率相比，能够平均节省大于50%的码率。2．高质量的视频画面：H.264能够在低码率情况下提供高质量的视频图像，在较低带宽上提供高质量的图像传输是H.264的应用亮点。3．提高网络适应能力：H.264可以工作在实时通信应用（如视频会议）低延时模式下，也可以工作在没有延时的视频存储或视频流服务器中。H264的优势：H.264最大的优势是具有很高的数据压缩比率，在同等图像质量的条件下，H.264的压缩比是MPEG-2的2倍以上，是MPEG-4的1.5～2倍。举个例子，原始文件的大小如果为88GB，采用MPEG-2压缩标准压缩后变成3.5GB，压缩比为25∶1，而采用H.264压缩标准压缩后变为879MB，从88GB到879MB，H.264的压缩比达到惊人的102∶1。低码率（Low Bit Rate）对H.264的高的压缩比起到了重要的作用，和MPEG-2和MPEG-4 ASP等压缩技术相比，H.264压缩技术将大大节省用户的下载时间和数据流量收费。尤其值得一提的是，H.264在具有高压缩比的同时还拥有高质量流畅的图像，正因为如此，经过H.264压缩的视频数据，在网络传输过程中所需要的带宽更少，也更加经济。PS：以上摘自百度百科。需要了解的可自行百度。 我们将采集到的视频数据编码为H264数据流，那采集到的原始视频数据是什么呢？实际上是YUV420格式的数据，上篇视频采集的文章记录了设置输出设备的输出格式为：kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange 表示原始数据的格式为YUV420。那我们为什么要设置输出为YUV420数据呢，YUV420数据是什么呢？这篇文章介绍的很详细YUV和RGB。简单来说有一下几点：1.YUV420采样数据大小为RGB格式的一半(采样数据后续涉及到推流，所以数据越小越好)。2.YUV格式所有编码器都支持，RGB格式却存在不兼容的情况。3.YUV420格式适用于便携式设备。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251#import &lt;UIKit&#x2F;UIKit.h&gt;#import &lt;VideoToolbox&#x2F;VideoToolbox.h&gt;@interface BBH264Encoder : NSObject- (void)encodeSampleBuffer:(CMSampleBufferRef)sampleBuffer;- (void)endEncode;@end#import &quot;BBH264Encoder.h&quot;@interface BBH264Encoder()&#x2F;** 记录当前的帧数 *&#x2F;@property (nonatomic, assign) NSInteger frameID;&#x2F;** 编码会话 *&#x2F;@property (nonatomic, assign) VTCompressionSessionRef compressionSessionRef;&#x2F;** 文件写入对象 *&#x2F;@property (nonatomic, strong) NSFileHandle *fileHandle;@end@implementation BBH264Encoder- (instancetype)init&#123; if (self &#x3D; [super init]) &#123; &#x2F;&#x2F; 1.初始化写入文件的对象(NSFileHandle用于写入二进制文件) [self setupFileHandle]; &#x2F;&#x2F; 2.初始化压缩编码的会话 [self setupCompressionSession]; &#125; return self;&#125;- (void)setupFileHandle &#123; &#x2F;&#x2F; 1.获取沙盒路径 NSString *file &#x3D; [[NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES) lastObject] stringByAppendingPathComponent:@&quot;test.h264&quot;]; &#x2F;&#x2F; 2.如果原来有文件,则删除 [[NSFileManager defaultManager] removeItemAtPath:file error:nil]; [[NSFileManager defaultManager] createFileAtPath:file contents:nil attributes:nil]; &#x2F;&#x2F; 3.创建对象 self.fileHandle &#x3D; [NSFileHandle fileHandleForWritingAtPath:file];&#125;- (void)setupCompressionSession&#123; &#x2F;&#x2F;0.用于记录当前是第几帧数据(画面帧数非常多) _frameID &#x3D; 0; &#x2F;&#x2F;1.清空压缩上下文 if (_compressionSessionRef) &#123; VTCompressionSessionCompleteFrames(_compressionSessionRef, kCMTimeInvalid); VTCompressionSessionInvalidate(_compressionSessionRef); CFRelease(_compressionSessionRef); _compressionSessionRef &#x3D; NULL; &#125; &#x2F;&#x2F;2.录制视频的宽度&amp;高度 int width &#x3D; [UIScreen mainScreen].bounds.size.width; int height &#x3D; [UIScreen mainScreen].bounds.size.height; &#x2F;&#x2F;3.创建压缩会话 OSStatus status &#x3D; VTCompressionSessionCreate(NULL, width, height, kCMVideoCodecType_H264, NULL, NULL, NULL, bbCompressionSessionCallback, (__bridge void * _Nullable)(self), &amp;_compressionSessionRef); &#x2F;&#x2F;4.判断状态 if (status !&#x3D; noErr) return; &#x2F;&#x2F;5.设置参数 &#x2F;&#x2F;Profile_level,h264的协议等级，不同的清晰度使用不同的ProfileLevel VTSessionSetProperty(_compressionSessionRef, kVTCompressionPropertyKey_ProfileLevel, kVTProfileLevel_H264_Baseline_AutoLevel); &#x2F;&#x2F; 关键帧最大间隔 VTSessionSetProperty(_compressionSessionRef, kVTCompressionPropertyKey_MaxKeyFrameInterval, (__bridge CFTypeRef _Nullable)(@(30))); &#x2F;&#x2F; 设置平均码率 单位是byte int bitRate &#x3D; [self getResolution]; CFNumberRef bitRateRef &#x3D; CFNumberCreate(kCFAllocatorDefault, kCFNumberSInt32Type, &amp;bitRate); VTSessionSetProperty(_compressionSessionRef, kVTCompressionPropertyKey_AverageBitRate, bitRateRef); &#x2F;&#x2F; 码率上限 接收数组类型CFArray[CFNumber] [bytes,seconds,bytes,seconds...] 单位是bps VTSessionSetProperty(_compressionSessionRef, kVTCompressionPropertyKey_DataRateLimits, (__bridge CFArrayRef _Nullable)@[@(bitRate*1.5&#x2F;8), @1]); &#x2F;&#x2F; 设置期望帧率 int fps &#x3D; 30; CFNumberRef fpsRef &#x3D; CFNumberCreate(kCFAllocatorDefault, kCFNumberIntType, &amp;fps); VTSessionSetProperty(_compressionSessionRef, kVTCompressionPropertyKey_ExpectedFrameRate, fpsRef); &#x2F;&#x2F; 设置实时编码 VTSessionSetProperty(_compressionSessionRef, kVTCompressionPropertyKey_RealTime, kCFBooleanTrue); &#x2F;&#x2F; 关闭重排Frame VTSessionSetProperty(_compressionSessionRef, kVTCompressionPropertyKey_AllowFrameReordering, kCFBooleanFalse); &#x2F;&#x2F; 设置比例16:9（分辨率宽高比） VTSessionSetProperty(_compressionSessionRef, kVTCompressionPropertyKey_AspectRatio16x9, kCFBooleanTrue); &#x2F;&#x2F;6.准备编码 VTCompressionSessionPrepareToEncodeFrames(_compressionSessionRef);&#125;&#x2F;**编码回调*&#x2F;static void bbCompressionSessionCallback(void * CM_NULLABLE outputCallbackRefCon,void * CM_NULLABLE sourceFrameRefCon,OSStatus status,VTEncodeInfoFlags infoFlags,CM_NULLABLE CMSampleBufferRef sampleBuffer )&#123; BBH264Encoder *encoder &#x3D; (__bridge BBH264Encoder *)(outputCallbackRefCon); &#x2F;&#x2F;1.判断状态是否为没有错误 if (status !&#x3D; noErr) &#123; return; &#125; CFArrayRef attachments &#x3D; CMSampleBufferGetSampleAttachmentsArray(sampleBuffer, false); BOOL isKeyframe &#x3D; NO; if (attachments !&#x3D; NULL) &#123; CFDictionaryRef attachment; CFBooleanRef dependsOnOthers; attachment &#x3D; (CFDictionaryRef)CFArrayGetValueAtIndex(attachments, 0); dependsOnOthers &#x3D; CFDictionaryGetValue(attachment, kCMSampleAttachmentKey_DependsOnOthers); dependsOnOthers &#x3D;&#x3D; kCFBooleanFalse ? (isKeyframe &#x3D; YES) : (isKeyframe &#x3D; NO); &#125; &#x2F;&#x2F;2.是否为关键帧 if (isKeyframe) &#123; &#x2F;&#x2F;SPS and PPS. CMFormatDescriptionRef format &#x3D; CMSampleBufferGetFormatDescription(sampleBuffer); size_t spsSize, ppsSize; size_t parmCount; const uint8_t* sps, *pps; OSStatus status &#x3D; CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 0, &amp;sps, &amp;spsSize, &amp;parmCount, NULL ); &#x2F;&#x2F;获取SPS无错误则继续获取PPS if (status &#x3D;&#x3D; noErr) &#123; CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 1, &amp;pps, &amp;ppsSize, &amp;parmCount, NULL ); NSData *spsData &#x3D; [NSData dataWithBytes:sps length:spsSize]; NSData *ppsData &#x3D; [NSData dataWithBytes:pps length:ppsSize]; &#x2F;&#x2F;写入文件 [encoder gotSpsPps:spsData pps:ppsData]; &#125;else&#123; return; &#125;&#125; &#x2F;&#x2F;3.前4个字节表示长度,后面的数据的长度 &#x2F;&#x2F; 除了关键帧,其它帧只有一个数据 char *buffer; size_t total; CMBlockBufferRef dataBuffer &#x3D; CMSampleBufferGetDataBuffer(sampleBuffer); OSStatus statusCodeRet &#x3D; CMBlockBufferGetDataPointer(dataBuffer, 0, NULL, &amp;total, &amp;buffer); if (statusCodeRet &#x3D;&#x3D; noErr) &#123; size_t offset &#x3D; 0; &#x2F;&#x2F;返回的nalu数据前四个字节不是0001的startcode，而是大端模式的帧长度length int const headerLenght &#x3D; 4; &#x2F;&#x2F;循环获取NAL unit数据 while (offset &lt; total - headerLenght) &#123; int NALUnitLength &#x3D; 0; &#x2F;&#x2F; Read the NAL unit length memcpy(&amp;NALUnitLength, buffer + offset, headerLenght); &#x2F;&#x2F;从大端转系统端 NALUnitLength &#x3D; CFSwapInt32BigToHost(NALUnitLength); NSData *data &#x3D; [NSData dataWithBytes:buffer + headerLenght + offset length:NALUnitLength]; &#x2F;&#x2F; Move to the next NAL unit in the block buffer offset +&#x3D; headerLenght + NALUnitLength; [encoder gotEncodedData:data isKeyFrame:isKeyframe]; &#125; &#125;&#125;&#x2F;**获取屏幕分辨率*&#x2F;- (int)getResolution&#123; CGRect screenRect &#x3D; [[UIScreen mainScreen] bounds]; CGSize screenSize &#x3D; screenRect.size; CGFloat scale &#x3D; [UIScreen mainScreen].scale; CGFloat screenX &#x3D; screenSize.width * scale; CGFloat screenY &#x3D; screenSize.height * scale; return screenX * screenY;&#125;- (void)gotSpsPps:(NSData*)sps pps:(NSData*)pps&#123; &#x2F;&#x2F; 1.拼接NALU的header const char bytes[] &#x3D; &quot;\\x00\\x00\\x00\\x01&quot;; size_t length &#x3D; (sizeof bytes) - 1; NSData *ByteHeader &#x3D; [NSData dataWithBytes:bytes length:length]; &#x2F;&#x2F; 2.将NALU的头&amp;NALU的体写入文件 [self.fileHandle writeData:ByteHeader]; [self.fileHandle writeData:sps]; [self.fileHandle writeData:ByteHeader]; [self.fileHandle writeData:pps];&#125;- (void)gotEncodedData:(NSData*)data isKeyFrame:(BOOL)isKeyFrame&#123; NSLog(@&quot;gotEncodedData %d&quot;, (int)[data length]); if (self.fileHandle !&#x3D; NULL) &#123; const char bytes[] &#x3D; &quot;\\x00\\x00\\x00\\x01&quot;; size_t length &#x3D; (sizeof bytes) - 1; &#x2F;&#x2F;string literals have implicit trailing &#39;\\0&#39; NSData *ByteHeader &#x3D; [NSData dataWithBytes:bytes length:length]; [self.fileHandle writeData:ByteHeader]; [self.fileHandle writeData:data]; &#125;&#125;- (void)encodeSampleBuffer:(CMSampleBufferRef)sampleBuffer &#123; &#x2F;&#x2F; 1.将sampleBuffer转成imageBuffer CVImageBufferRef imageBuffer &#x3D; (CVImageBufferRef)CMSampleBufferGetImageBuffer(sampleBuffer); &#x2F;&#x2F; 2.根据当前的帧数,创建CMTime的时间 CMTime presentationTimeStamp &#x3D; CMTimeMake(self.frameID++, 1000); VTEncodeInfoFlags flags; &#x2F;&#x2F; 3.开始编码该帧数据 OSStatus statusCode &#x3D; VTCompressionSessionEncodeFrame(self.compressionSessionRef, imageBuffer, presentationTimeStamp, kCMTimeInvalid, NULL, (__bridge void * _Nullable)(self), &amp;flags); if (statusCode &#x3D;&#x3D; noErr) &#123; NSLog(@&quot;H264: VTCompressionSessionEncodeFrame Success&quot;); &#125;&#125;- (void)endEncode &#123; VTCompressionSessionCompleteFrames(self.compressionSessionRef, kCMTimeInvalid); VTCompressionSessionInvalidate(self.compressionSessionRef); CFRelease(self.compressionSessionRef); self.compressionSessionRef &#x3D; NULL; [self.fileHandle closeFile]; self.fileHandle &#x3D; NULL;&#125;@end 上述H264码流的NALU和SPS、PPS是什么呢？关于H264码流结构NALU、SPS\\PPS。此代码是将采集到的原始数据编码为H.264码流写入本地文件，此文件可以利用VLC播放器直接播放，测试结果，注意需要真机测试。真机获取沙盒文件的方法请见:真机获取沙盒文件。感谢coderWhy和iOSSinger两位的分享。","categories":[{"name":"iOS音视频技术","slug":"iOS音视频技术","permalink":"http://yoursite.com/categories/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"}]},{"title":"iOS音视频开发-视频会话捕捉","slug":"iOS音视频开发-视频会话捕捉","date":"2018-02-05T06:45:08.000Z","updated":"2020-04-10T07:18:04.778Z","comments":true,"path":"2018/02/05/iOS音视频开发-视频会话捕捉/","link":"","permalink":"http://yoursite.com/2018/02/05/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91-%E8%A7%86%E9%A2%91%E4%BC%9A%E8%AF%9D%E6%8D%95%E6%8D%89/","excerpt":"","text":"iOS音视频开发抽出时间整理一下，权当备忘吧。iOS音视频开发原理文章在网上有很多了，就不记录了。后面会记录每步骤的实现。 音视频开发首先需要捕捉视频会话，这里只是捕获了视频会话，音频会话后续会记录。废话少说，贴代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#import &lt;UIKit&#x2F;UIKit.h&gt;@interface BBVideoCapture : NSObject&#x2F;**开始捕获视频@param preview 捕获视频显示的父控件*&#x2F;- (void)startCapture:(UIView *)preview;&#x2F;**结束捕获视频*&#x2F;- (void)stopCapture;@end#import &lt;AVFoundation&#x2F;AVFoundation.h&gt;#import &quot;BBVideoCapture.h&quot;@interface BBVideoCapture () &lt;AVCaptureVideoDataOutputSampleBufferDelegate&gt;&#x2F;** 捕捉画面执行的线程队列 *&#x2F;@property (nonatomic, strong) dispatch_queue_t captureQueue;&#x2F;** 捕捉会话*&#x2F;@property (nonatomic, weak) AVCaptureSession *captureSession;&#x2F;** 预览图层 *&#x2F;@property (nonatomic, weak) AVCaptureVideoPreviewLayer *previewLayer;@end@implementation BBVideoCapture- (void)startCapture:(UIView *)preview&#123; &#x2F;&#x2F; 1.创建捕捉会话 AVCaptureSession *session &#x3D; [[AVCaptureSession alloc] init]; session.sessionPreset &#x3D; AVCaptureSessionPresetHigh; self.captureSession &#x3D; session; &#x2F;&#x2F; 2.设置输入设备 AVCaptureDevice *device &#x3D; [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo]; &#x2F;&#x2F; 2.1自动变焦 if([device isFocusModeSupported:AVCaptureFocusModeContinuousAutoFocus])&#123; if([device lockForConfiguration:nil])&#123; device.focusMode &#x3D; AVCaptureFocusModeContinuousAutoFocus; &#125; &#125; NSError *error &#x3D; nil; AVCaptureDeviceInput *input &#x3D; [[AVCaptureDeviceInput alloc] initWithDevice:device error:&amp;error]; if ([session canAddInput:input]) &#123; [session addInput:input]; &#125; &#x2F;&#x2F; 3.添加输出设备 AVCaptureVideoDataOutput *output &#x3D; [[AVCaptureVideoDataOutput alloc] init]; self.captureQueue &#x3D; dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0); [output setSampleBufferDelegate:self queue:self.captureQueue]; &#x2F;&#x2F; 3.1kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange 表示原始数据的格式为YUV420 &#x2F;&#x2F; 这里YUV420为后续编码设置，暂时可忽略，后续会写。 NSDictionary *settings &#x3D; [[NSDictionary alloc] initWithObjectsAndKeys:[NSNumber numberWithUnsignedInt:kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange], kCVPixelBufferPixelFormatTypeKey, nil]; output.videoSettings &#x3D; settings; output.alwaysDiscardsLateVideoFrames &#x3D; YES; if ([session canAddOutput:output]) &#123; [session addOutput:output]; &#125; &#x2F;&#x2F; 4.设置录制视频的方向 AVCaptureConnection *connection &#x3D; [output connectionWithMediaType:AVMediaTypeVideo]; [connection setVideoOrientation:AVCaptureVideoOrientationPortrait]; &#x2F;&#x2F; 5.添加预览图层 AVCaptureVideoPreviewLayer *previewLayer &#x3D; [[AVCaptureVideoPreviewLayer alloc] initWithSession:session]; previewLayer.frame &#x3D; preview.bounds; [preview.layer insertSublayer:previewLayer atIndex:0]; self.previewLayer &#x3D; previewLayer; &#x2F;&#x2F; 6.开始捕捉 [self.captureSession startRunning];&#125;- (void)stopCapture &#123; [self.captureSession stopRunning]; [self.previewLayer removeFromSuperlayer];&#125;#pragma mark - 获取视频数据代理- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection &#123; &#x2F;**这里就是捕获到视频数据的地方，后续再这里实现视频编码*&#x2F;&#125;@end 视频捕获会话相对较简单，代码中注释很详细，入门时参考了很多资料，感谢分享者，此代码很多参考coderWhy的分享，当然存在自己优化与改动，再次感谢！","categories":[{"name":"iOS音视频技术","slug":"iOS音视频技术","permalink":"http://yoursite.com/categories/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"}]},{"title":"使用Hexo搭建个人Github.io博客","slug":"使用Hexo搭建个人Github-io博客","date":"2018-02-01T06:14:33.000Z","updated":"2020-04-10T07:19:32.274Z","comments":true,"path":"2018/02/01/使用Hexo搭建个人Github-io博客/","link":"","permalink":"http://yoursite.com/2018/02/01/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BAGithub-io%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"回想当初，想要搭建自己的个人博客的冲动是怎样产生的？知识匮乏，无人指导，独自摸索，迷茫的徘徊在无知的十字路口（无知：管我什么事啊？）。好在现今网络发达，富有分享精神的coder，犹如繁星指路，感谢我成长路上帮助到我的coder们。分享者们搭建富有极客风格的个人博客，发表技术含量较高的技术文章，学习知识之余，不乏搭建个人博客的想法，向其学习，学习知识、分享知识，同时也是一种提升自身方式。不过搭建博客的想法终究是想法，工(zhao)作(ge)一(jie)忙(kou)，想法就搁置了… Hexo1.什么是HexoHexo官方网站的醒目标题：A fast, simple &amp; powerful blog framework！其寓意言简意赅：一个快速、简单和功能强大的博客框架！Hexo基于Node.js的静态博客程序，可以方便将生成的静态网页托管到Github上，可以随意设置丰富、优秀的主题。研究了一天时间，搭建了极简风格的个人博客，记录一下，未涉及到的功能，后续会继续学习使用。 1.Hexo的官方文档写的很详细，文档见官方文档,可以切换为简体中文，很方便。2.什么是NexTNexT是一种优雅、漂亮的Hexo主题。 NexT主题，正如官网所说精于心，简于形。我比较喜欢简单不失优雅的风格。1.NexT使用方法官方文档http://theme-next.iissnan.com/getting-started.html2.记录一下设置过程中我遇到的问题。下载主题的时候会有最新和稳定版本之分，当初我就下载的最新版本，然后根据文档设置的主题风格，然后困扰了我很久的问题就出现了。next版本在设置菜单的时候，不要按照文档更改菜单设置，就是不用更改任何菜单设置就可以，因为按照文档更改之后，菜单的图片显示不了。因为next里面的实现变了。下载的主题配置：主题配置菜单的时候官方文档有个坑~箭头所指的地方应该没有空格才会正确显示和响应菜单栏，如下：其他就没有什么问题了，按照官方文档设置你想要的风格。后续添加其他的小功能，比如评论、统计等等，并不是真正的需要这些功能，这完全是自己好奇心，去了解这是如何做可以更加像一个完整的Blog。 做自己喜欢的事，就是最幸福的事。第一次使用，惯例：Say： Hello world！bye~","categories":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/categories/%E5%85%B6%E5%AE%83/"}],"tags":[{"name":"随想","slug":"随想","permalink":"http://yoursite.com/tags/%E9%9A%8F%E6%83%B3/"}]}],"categories":[{"name":"iOS音视频技术","slug":"iOS音视频技术","permalink":"http://yoursite.com/categories/iOS%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF/"},{"name":"其它","slug":"其它","permalink":"http://yoursite.com/categories/%E5%85%B6%E5%AE%83/"}],"tags":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"},{"name":"随想","slug":"随想","permalink":"http://yoursite.com/tags/%E9%9A%8F%E6%83%B3/"}]}